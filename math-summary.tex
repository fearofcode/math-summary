\documentclass{article}

\usepackage{epigraph}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{axiom}{Axiom}[section]
\newtheorem{corollary}{Corollary}[section]

\makeatletter
\def\th@plain{%
  \thm@notefont{}% same as heading font
  \itshape % body font
}
\def\th@definition{%
  \thm@notefont{}% same as heading font
  \normalfont % body font
}
\makeatother

\begin{document}

\title{Math summary for actually understanding machine learning}
\author{Warren Henning\\\texttt{warren.henning@gmail.com}}
\date{\today}

\maketitle

\tableofcontents

\pagebreak

\epigraph{Do not ask permission to understand. Do not wait for the word of authority. Seize reason in your own hand. With your own teeth savor the fruit.}{Strichartz, \cite{strichartz}}

\epigraph{We shall not cease from exploration. And the end of all our exploring will be to arrive where we started and know the place for the first time.}{T. S. Eliot}

\epigraph{Dimidium facti qui coepit habet: sapere aude (``He who has begun is half done: dare to know").}{Horace}

\epigraph{What we hope ever to do with ease, we must first learn to do with diligence.}{Samuel Johnson}

\epigraph{Get your fundamentals on lock so that you can start getting into the ill advanced shit. This is universally applicable.}{Earl Sweatshirt}

\section{Disclaimer}

I haven't taken a university math course in many years. There may very well
be typos and outright mathematical errors!

Strictly speaking, I have no business writing this.

\section{Introduction}

This document is intended to do two things: first, to summarize key theorems of difficult mathematical subjects as I'm studying them for my own purposes. Eventually, it would be nice to have this be a summary of the math needed for machine learning. But for now, things will be even more terse than an upper-division textbook.

I want to actually understand what's going on in machine learning. That means having a solid background in core pure and applied mathematics as well as probability and statistics. Following cookbook recipes for machine learning libraries is wonderful up until it doesn't work or produces something that doesn't make sense. Then you're fucked because you don't know what's going on. Googling for what could be happening yields weird stuff that makes your eyes glaze over, and then you realize you're both in way over your head and \emph{proper fucked}.

So the goal is to avoid that by having enough background to know what's going on numerically and statistically in a rigorous way. That will hopefully let us choose the right tool to begin with: do we actually need a neural network at all? Can we get away with a simple linear model? Why or why not? Can we even do any better than a simple naive Bayes classifier? The tutorials and ``data science" material won't answer these questions. They spend so much time ``visualizing" data and then writing Medium.com blog posts about a cool D3.js trick they found while doing so that they apparently don't stop to think whether what they're doing actually makes sense from a mathematical perspective.

Also, I want to apply this stuff to actual interesting problems, not just better ways to push ads onto users' screens.

Any attempts to water things down is a recipe for fallacious thinking, not that the tech industry has a problem embracing illogical things if it suits their selfish motives.

Not everything here is actually necessary to understand machine learning. It's just stuff I learned on my way there. It's a general goal I have to cultivate mathematical maturity, and pretty much anything in math is fair game for developing that.

Interspersed between the main definitions and theorems are comments that themselves contain claims which generally require rigorous proof and are not trivial by any means. The proofs of those claims are omitted here because this document is not intended to be a substitute for the many excellent textbooks that are available. See Section \ref{bibliography} for the books I used to create this. Maybe it would be better to separate them out as propositions in of themselves the way I do with other facts below, but I've tried to focus on just the essentials. Again, this is not a textbook, and I'm assuming the material here is already known.

\section{Basic Stuff}

\subsection{Triangle Inequality}
Let $|x|$ be the absolute value of $x$.

\begin{equation} \label{triangle-inequality}
|a + b| \leq |a| + |b| 
\end{equation}

for all $a, b \in \mathbb{R}$. Geometrically, it has the interpretation that the shortest path between any two points is a straight line.

\subsection{Sets}

The following comes from Smith's \textit{Introductory Mathematics: Algebra and Analysis} \cite{smith}, which is a lovely book completely worth the exorbitant Springer purchase price for the jokes interspersed between mathematical content alone.

Let $A$, $B$, and $C$ be sets.

\begin{theorem}[Distributive law of intersection over union]
$\\ A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$.
\end{theorem}

\begin{theorem}[Distributive law of union over intersection] \label{distributive-law-2}
$\\ A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$.
\end{theorem}

These are analogous to distributive laws of fields such as $\mathbb{Q}$ and $\mathbb{R}$.

The standard, direct way to prove two sets $A$ and $B$ are equal is to take $x \in A$ and show that it's in $B$, establishing that $A \subset B$\footnote{Note that $\subset$ is used here to mean ``subset" (i.e., subset or equal), not ``strict subset." We could alternatively use $\subseteq$, but that's a whole two extra characters in \LaTeX.}, and then conversely show that $x \in B$ implies $x \in A$, showing that $B \subset A$. Then $A = B$ by definition. Here's an example of this to prove Theorem \ref{distributive-law-2}:

\begin{proof}
Let $x \in A \cup (B \cap C)$. Then $x \in A$ or $x \in B \cap C$. If $x \in A$, $x \in A \cup B$ and $x \in A \cup C$, so $x \in (A \cup B) \cap (A \cup C)$. If $x \notin A$, $x \in B \cap C$, so $x \in A \cup B$ and $x \in A \cup C$, so $x \in (A \cup B) \cap (A \cup C)$. So $A \cup (B \cap C) \subset (A \cup B) \cap (A \cup C)$.

Now suppose $x \in (A \cup B) \cap (A \cup C)$. This implies $x \in A$, so $x \in A \cup (B \cap C)$. So $(A \cup B) \cap (A \cup C) \subset A \cup (B \cap C)$.

These two facts together suffice to show that the two sets are equal, so we are done.
\end{proof} 

\begin{definition}
Let $A$ and $U$ (called the \textbf{universe}) be sets. Suppose $A \subset U$. Then $A' = U \setminus A$ is the \textbf{complement} of $A$.
\end{definition}

\begin{theorem}[De Morgan's Laws]
Let $A$ and $B$ be subsets of some fixed set.

\begin{align}
(A \cup B)' = A' \cap B' \\
(A \cap B)' = A' \cup B'
\end{align}
\end{theorem}

These are easy to see with a Venn diagram or by comparing to the logical version of them you can find on Wikipedia. I would draw one here but doing that in \LaTeX \ is a pain in the ass. Sorry, just draw it on paper or Google it if you're curious.

\subsection{Maps}

Let $f: A \rightarrow B$ be a mapping from sets $A$ to $B$.

\begin{definition}
$A$ is the \textbf{domain} and $B$ the \textbf{codomain}. $f(X) = \{f(x) \ | \ x \in A\} \subset B$ is the \textbf{range} of $f$, also called the \textbf{image} of $f$.
\end{definition}

\begin{definition}
$f$ is \textbf{surjective} or \textbf{onto} if $\forall b \in B$, $\exists a \in A$ s.t. $f(a) = b$. $f$ is a \textbf{surjection}.
\end{definition}

\begin{proposition}
If the codomain of $f$ is equal to the range, $f$ is surjective.
\end{proposition}

\begin{definition}
$f$ is \textbf{injective} or \textbf{1-1} if $a \neq a' \implies f(a) \neq f(a')$, $a, a' \in A$. $f$ is an \textbf{injection}.
\end{definition}

Taking the contrapositive of the previous definition, if $f$ is 1-1 and $f(a) = f(a')$, then $a = a'$. So you can show $f$ is injective by assuming $f(a) = f(b)$ for some $a$, $b$ $\in A$ and showing that $a = b$.

\begin{definition}
If $f$ is both injective and surjective, $f$ is \textbf{bijective} or a \textbf{bijection}.
\end{definition}

\begin{definition}
$f$ is \textbf{invertible} if there exists $g: Y \rightarrow B$ such that 

\begin{center}
$y = f(x) \iff x = g(y)$ for all $x \in X$, $y \in Y$.
\end{center}

\end{definition}

\begin{proposition}
Being bijective is a necessary and sufficient condition for being invertible. If it is invertible, its inverse is unique.
\end{proposition}

\begin{definition}
Two sets have the same cardinality if there is a bijection between them.
\end{definition}

\begin{proposition}
A composition $g \ \circ \ f : A \rightarrow C  = g(f(x)) $ of two injective maps $f : A \rightarrow B$, $g: B \rightarrow C$ is injective. \\
A composition of two surjective maps is surjective. \\
A composition of two bijective maps is bijective.
\end{proposition}

\subsection{Relations, equivalence relations, partitions}

Let $S$ be a set and $s, t, u \in S$ throughout this section.

\begin{definition}
A \textbf{relation} $\bowtie$ on $S$ is a subset of $S \times S$. Write $s \bowtie t$ if $(s, t) \in \ \bowtie$.
\end{definition}

\begin{definition}
$\bowtie$ is \textbf{reflexive} if $s \bowtie s$ $\forall s \in S$. \\
$\bowtie$ is \textbf{symmetric} if $s \bowtie t \implies t \bowtie s$. \\
$\bowtie$ is \textbf{transitive} if $s \bowtie t$ and $t \bowtie u \implies s \bowtie u$. \\
$\bowtie$ is an \textbf{equivalence relation} if is reflexive, symmetric, and transitive.
\end{definition}

Of course the most familiar example of an equivalence relation is $=$. But consider also the set of lines in the plane and the relation $||$, where $l_1 \ || \ l_2$ means $l_1$ is parallel to $l_2$. Then $||$ is an equivalence relation. Likewise with the congruence operator $\cong$ on triangles in the plane.

\begin{definition}
A \textbf{partition} of $S$ is a collection of non-empty, mutually disjoint subsets whose union is $S$.
\end{definition}

To show that a collection of sets $\{ C_1, \ldots, C_n \}$ is a partition of $S$ for $n \ge 1$:

\begin{itemize}
\item Show that $C_i \neq \emptyset$ $\forall i$
\item Show that $C_i \cap C_j = \emptyset$ $\forall \ i \neq j$
\item Show that $x \in S \implies x \in C_i$ for some $i$
\end{itemize}

An example would be partitioning the plane with lines (possibly an infinite number).

Equivalence relations also partition the set into \textbf{equivalence classes}:

\begin{definition}
Let $\sim$ be an equivalence relation on $S$ and $x \in S$. \\
$[x] = \{ y \ | \ y \in S, x \sim y\}$ is the \textbf{equivalence class} of $x$.
\end{definition}

\begin{proposition}
$\{[x] \ | \ x \in S \}$ is a partition of $S$.
\end{proposition}

\section{Calculus and Analysis}

The following is taken from various calculus/analysis books, including Spivak's {\it Calculus} \cite{spivak} and Ross' {\it Elementary Analysis} \cite{ross}. Examples often correspond to exercise in the texts and the order follows that of the books. Although I drew this from multiple books, the amount of overlap between them is pretty high, although clearly analysis books will focus more on theory and less on calculation than a calculus book. So if for some reason you're considering what book to buy, there are pretty much only four categories of book to consider:

\begin{itemize}
\item Standard computational introductory calculus book, few or no proofs. This document is almost certainly unreadable if you have not at least gotten as far as that in the standard academic learning path found in North America.
\item Rigorous calculus book suitable for an honors calculus course\footnote{which is different from AP Calculus classes offered in high schools, which is super computational and is easy to get a 5 on without knowing why the calculations you're doing work}, like \cite{spivak}
\item Introductory analysis book, like \cite{ross}
\item Rigorous undergraduate analysis book (which I haven't gotten to yet)
\end{itemize}

\subsection{Bounds, sup, inf, the Completeness Axiom}

Let $S \subset \mathbb{R}$, $S \neq \emptyset, m, M \in \mathbb{R}$. 

\begin{definition}
If $s_0 \in S$ and $s_0 \ge s$ $\forall s \in S$, write $\max S = s_0$. $s_0$ is the \textbf{maximum} of $S$.
\end{definition}

\begin{definition}
If $s_0 \in S$ and $s_0 \le s$ $\forall s \in S$, write $\min S = s_0$. $s_0$ is the \textbf{minimum} of $S$.
\end{definition}

\begin{definition}
If $s \leq M$ $\forall s \in S$, $M$ is an \textbf{upper bound} of $S$. S is \textbf{bounded above}.
\end{definition}

\begin{definition}
If $m \leq s$ $\forall s \in S$, $m$ is a \textbf{lower bound} of $S$. S is \textbf{bounded below}.
\end{definition}

\begin{definition}
If $S$ is both bounded above and bounded below, $S$ is \textbf{bounded}. So $\exists$ $m, M$ s.t. $S \subset [m, M]$.
\end{definition}

\begin{definition}
If $M$ is an upper bound and $M \leq B$ for all other upper bounds $B$, $M$ is a \textbf{least upper bound} or \textbf{supremum} of $S$. Write sup $S = M$.
\end{definition}

\begin{definition}
If $m$ is a lower bound and $m \geq b$ for all other lower bounds $b$, $m$ is a \textbf{greatest lower bound} or \textbf{infimum} of $S$. Write inf $S = m$.
\end{definition}

Imagine having a bunch of points on a number line and moving a pencil from left to right until it hit upon a point on the line. That would be an infimum. Going from the opposite direct, right to left, would give a supremum. Note that the infimum and supremum do not need to be in $S$.

\begin{proposition}
If a set $S$ has a least upper bound, it is unique.
\end{proposition}

\begin{proof}
Suppose there are two least upper bounds of $S$, call them $r$ and $s$. It's easy to show that $r = s$, and therefore there's only one supremum. We can just apply the definition of what a least upper bound is here: as $s$ is an upper bound and $r$ is a least upper bound, $r \leq s$, by definition of $r$ being a least upper bound. Likewise as $r$ is an upper bound and $s$ is a least upper bound, $s \leq r$. (Again, this is just applying the fact that each is a least upper bound, so it's $\leq$ all upper bounds, including, in particular, one another.) So as $r \leq s$ and $s \leq r$, $r = s$.
\end{proof}

\begin{axiom}[Completeness Axiom, a.k.a. Least Upper Bound Property]
Every nonempty subset $S$ of $\mathbb{R}$ that is bounded above has a least upper bound $\sup S \in\mathbb{R}$.
\end{axiom}

\begin{corollary}
Every nonempty subset $S$ of $\mathbb{R}$ that is bounded below has a greatest lower bound $\inf S \in\mathbb{R}$.
\end{corollary}

\begin{proof}
Since $S$ is bounded below, $\exists$ $m \in \mathbb{R}$ s.t. $m \leq s$, $s \in S$.

Let $-S = \{ -s : s \in S \}$. Then $-m \ge -s$, so $-S$ is bounded above. So $\sup -S$ exists.

It can be shown that $\inf S = - \sup -S$, so $\inf S$ exists.

\end{proof}


\begin{example} \label{supexample}
Let $a \in \mathbb{R}$. Let $S = \{r \in \mathbb{R} : 0 \leq r < a\}$. Then we claim the obvious fact that $\sup S = a$, which we will now try to prove somewhat carefully in a pattern reminiscent of other proofs of other facts that are not as entirely obvious. First, observe that $S$ is not empty\footnote{while this is obvious, it's an important step to go through in order to be able to apply the least upper bound property} as, e.g., $a - 1 \in S$. So by the least upper bound property, $\sup S$ exists. Let $r = \sup S$. We are claiming that $r = a$. We prove this by contradiction. To do this, suppose $r \neq a$. Then either $r < a$ or $r > a$. For the first case, suppose $r < a$. Then we can find an element between $r$ and $a$ in order to reach a contradiction. Let $s = r + (a - r)/2$ (the midpoint between $r$ and $a$). Then $0 \leq s < a$, so $s \in S$. But also $a > r$, so $r$ would not actually be an upper bound (since it is not greater than or equal to $a$), a contradiction. Now suppose $r > a$. But then $a$ is an upper bound for $S$ and $a < r$, contradicting the minimality of $r$. So we must have that $r = a$.
\end{example}

The least upper bound property does not apply to, e.g., $\mathbb{Q}$. Any subset of $\mathbb{Q}$ whose least upper bound is irrational is an example of this, such as $\{r \in \mathbb{Q} : 0 \leq r < \sqrt{2}\}$ (since $\sqrt{2} \notin \mathbb{Q}$). Linear algebra classes will often just assume a vector space over a field $\mathbb{F}$, and the results apply to any such field, including $\mathbb{Q}$ and $\mathbb{R}$. But any result predicated on the least upper bound property does not apply to the rationals (as well as many other sets, but including the rationals in particular, which otherwise have the properties of what we intuitively think about with numbers).

Constructing sets and taking their minimum or maximum element is a common tactic in mathematics.

The least upper bound property can be used to prove the existence of square roots. Taking the minimum element of a set is a standard technique for proving the division algorithm for integers.  It's also great for creating proofs that an average undergraduate student would never think of in a reasonable amount of time left to their own devices! I definitely never saw that proof technique or thought of it until I took an upper division math course in college.

\begin{proposition}
Say $\sup S \in S$. Then $\sup S \ge s$ $\forall s \in S$, so by definition $\sup S = \max S$.
\end{proposition}

\begin{proposition} \label{bound-comparison}
Let $S$ be bounded and nonempty. Then $\inf S$ and $\sup S$ exist. Let $s \in S$. Then $\inf S \le s \le \sup S$.
So $\inf S \le \sup S$.
\end{proposition}

\begin{proposition}
In Proposition \ref{bound-comparison}, suppose $\inf S = \sup S$. Then $\inf S = s = \sup S$, so $S = \{s\}$.
\end{proposition}

\subsection{Limits}


\begin{definition}[$(\epsilon, \delta)$ limit of a function]

Let $f: \mathbb{R} \to \mathbb{R}$ be a function. 

\begin{equation}
\lim_{x \to a} f(x) = L
\end{equation}

if for every $\epsilon > 0$ there exists $\delta > 0$ such that if $0 < |x-a| <
\delta$, then $|f(x) - L| < \epsilon$.
 
\end{definition}

This formalizes the idea of being able to take $f(x)$ as close to $L$ as we want
by making $x$ sufficiently close to $a$.

Actually proving these winds up being an exercise in grappling with bullshit
absolute value expressions. Your basic plan of attack will probably be to let
$\epsilon > 0$ and find a suitable expression for $\delta$ in terms of
$\epsilon$ so that $|f(x) -L| < \epsilon$ once $|x-a|< \delta$ is assumed.

\begin{example} 

\emph{Show that $\lim_{x \to 1} (3x-1) = 2$}.

Substituting $f(x) = 3x-1$, $a = 1$, and $L = 2$ into the definition of a limit,
we want to show that

\begin{equation}
|x - 1| < \delta \implies |3x - 3| < \epsilon.
\end{equation}

This example was clearly chosen because the algebra works out nicely. It
works out like so: $|3x-3| = |3(x-1)| = 3|x-1| < \epsilon \implies |x-1| <
\epsilon/3$, so $\delta = \epsilon/3$ is a suitable choice.

Then $|x - 1| < \epsilon/3 \implies |3x-3| = |(x - 1) + (2x-2)| \leq |x-1| +
|2x-2| = |x-1| + 2|x-1| < \epsilon/3 + 2 \cdot \epsilon/3 = \epsilon,$ so we are
done.

Note that we have used Eq. \ref{triangle-inequality} above.
 
\end{example}

As you can no doubt surmise, with harder examples this shit gets really depressing.

Limits compose the way you'd expect:
\begin{proposition}
Suppose $\lim_{x \to a} f(x) = L$ and $\lim_{x \to a} g(x) = M$. Then

\begin{align}
\lim_{x \to a} f(x) + g(x) & = L + M \\
\lim_{x \to a} f(x)g(x) & = L \cdot M \\
\lim_{x \to a} \left(\frac{f}{g}\right)(x) & = \frac{L}{M}
\end{align}

Assuming everything above is defined.

\end{proposition}

If you can show that the positive ($\lim_{x \to a^{+}} f(x)$) and negative
($\lim_{x \to a^{-}} f(x) $) limits of a function are
different, it follows that the limit does not exist.


\subsection{Continuity}

\begin{definition}

$f$ is \textbf{continuous} at $a$ if

\begin{equation}
\lim_{x \to a} f(x) = f(a).
\end{equation}

\end{definition}

Of course continuous functions compose as you'd expect.

\begin{proposition}

If $f$ and $g$ are continuous at $a$, then $f+g$ and $f \cdot g$ are continuous
at $a$. If $g(a) \neq 0$, $1/g$ is continuous at $a$.

\end{proposition}

\begin{proof}

This follows from the definition of continuity and the previous limit
theorem. $\lim_{x \to a} (f(x) + g(x)) = \lim_{x \to a} f(x) + \lim_{x \to a}
g(x) = f(a) + g(a)$, so $f + g$ is continuous at $a$ by definition of
continuity. Replacing $+$ with $\cdot$ and using the previous limit theorem, the
rest of the result follows.

\end{proof}

The key thing that happens with a continuous function is that there's an
interval around $a$ that will share the properties of $f(a)$, like sign.

\subsection{Derivatives}

\begin{definition} 
$f$ is \textbf{differentiable} at $a$ if

\begin{equation}
\lim_{h \to 0} \frac{f(x+h) - f(x)}{h}
\end{equation}

exists.
\end{definition}

Recall the geometric interpretation of $f'(x)$ as being the slope of a line
tangent to $f(x)$; $f'(x)$ is like a secant line on a function between two
points of infinitely small distance. The physical interpretation of $f'(x)$ as
velocity and $f''(x)$ as acceleration should be familiar.

Every differentiable function is continuous, but not every continuous function is differentiable. The standard example of this is $f(x) = |x|$.

\begin{proposition}[Product Rule] 

If $f$ and $g$ are differentiable, 

\begin{equation}
(f \cdot g)' = f'g + g'f.
\end{equation}


\end{proposition} 

This generalizes recursively; $(f \cdot g \cdot h)' = f'gh + fg'h + fgh'$, and
so on. Notice the symbolic symmetry of it: sum the product of all the functions,
differentiating each one in turn.

\begin{proposition}[Chain Rule]

If $f$ and $g$ are differentiable,

\begin{equation}
(f \circ g)'(x) = f'(g)g'(x).
\end{equation}


\end{proposition}

\subsubsection{Derivative formulas}

\begin{equation}
\left(\frac{f}{g}\right)' = \frac{f'g - g'f}{g^2}
\end{equation}

\begin{equation}
(x^n)' = nx^{n-1}
\end{equation}

\section{Books I copied this stuff from} \label{bibliography}

\begin{thebibliography}{9}

\bibitem{ross}
  Kenneth A. Ross,
  \emph{Elementary Analysis: The Theory of Calculus}.
  Springer-Verlag,
  1st Edition,
  2013.

\bibitem{smith}
  Geoff Smith,
  \emph{Introductory Mathematics: Algebra and Analysis},
  Springer-Verlag,
  1998.

\bibitem{spivak}
  Michael Spivak,
  \emph{Calculus}.
  Publish or Perish,
  4th Edition,
  2008.

\bibitem{strichartz}
  Robert Strichartz,
  \emph{The Way of Analysis}.
  Jones and Bartlett Publishers,
  2000.
  
\end{thebibliography}

\section{License}

This document is freely shareable under the terms of the GNU Free Documentation
license; see LICENSE in this document's directory for more information.

\end{document}

