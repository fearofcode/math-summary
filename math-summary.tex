\documentclass{article}

\usepackage{epigraph}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{axiom}{Axiom}
\newtheorem{corollary}{Corollary}

\makeatletter
\def\th@plain{%
  \thm@notefont{}% same as heading font
  \itshape % body font
}
\def\th@definition{%
  \thm@notefont{}% same as heading font
  \normalfont % body font
}
\makeatother

\begin{document}

\title{Math summary for actually understanding machine learning}
\author{Warren Henning\\\texttt{warren.henning@gmail.com}}
\date{\today}

\maketitle

\tableofcontents

\pagebreak

\section{Disclaimer}

I haven't taken a university math course in many years. There may very well
be typos and outright mathematical errors!

Strictly speaking, I have no business writing this.

\section{Introduction}

\epigraph{Do not ask permission to understand. \\ Do not wait for the word of authority. \\ Seize reason in your own hand. \\ With your own teeth savor the fruit.}{Strichartz, \cite{strichartz}}

This document is intended to do two things: first, to summarize key theorems of difficult mathematical subjects as I'm studying them for my own purposes. Eventually, it would be nice to have this be a summary of the math needed for machine learning. But for now, things will be even more terse than an upper-division textbook.

I want to actually understand what's going on in machine learning. That means having a solid background in core pure and applied mathematics as well as probability and statistics. Following cookbook recipes for machine learning libraries is wonderful up until it doesn't work or produces something that doesn't make sense. Then you're fucked because you don't know what's going on. Googling for what could be happening yields weird stuff that makes your eyes glaze over, and then you realize you're both in way over your head and \emph{proper fucked}.

So the goal is to avoid that by having enough background to know what's going on numerically and statistically in a rigorous way. That will hopefully let us choose the right tool to begin with: do we actually need a neural network at all? Can we get away with a simple linear model? Why or why not? Can we even do any better than a simple naive Bayes classifier? The tutorials and ``data science" material won't answer these questions. They spend so much time ``visualizing" data and then writing Medium.com blog posts about a cool D3.js trick they found while doing so that they apparently don't stop to think whether what they're doing actually makes sense from a mathematical perspective.

Also, I want to apply this stuff to actual interesting problems, not just better ways to push ads onto users' screens.

Any attempts to water things down is a recipe for fallacious thinking, not that the tech industry has a problem embracing illogical things if it suits their selfish motives.

Not everything here is actually necessary to understand machine learning. It's just stuff I learned on my way there. It's a general goal I have to cultivate mathematical maturity, and pretty much anything in math is fair game for developing that.

\section{Basic Stuff}

\subsection{Triangle Inequality}
Let $|x|$ be the absolute value of $x$.

\begin{equation} \label{triangle-inequality}
|a + b| \leq |a| + |b| 
\end{equation}

for all $a, b \in \mathbb{R}$. Geometrically, it has the interpretation that the shortest path between any two points is a straight line.

\section{Sets}

The following comes from Smith's \textit{Introductory Mathematics: Algebra and Analysis} \cite{smith}, which is a lovely book completely worth the exorbitant Springer purchase price for the jokes interspersed between mathematical content alone.

Let $A$, $B$, and $C$ be sets.

\begin{theorem}[Distributive law of intersection over union]
$\\ A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$.
\end{theorem}

\begin{theorem}[Distributive law of union over intersection] \label{distributive-law-2}
$\\ A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$.
\end{theorem}

These are analogous to distributive laws of fields such as $\mathbb{Q}$ and $\mathbb{R}$.

The standard, direct way to prove two sets $A$ and $B$ are equal is to take $x \in A$ and show that it's in $B$, establishing that $A \subset B$\footnote{Note that $\subset$ is used here to mean ``subset" (i.e., subset or equal), not ``strict subset." We could alternatively use $\subseteq$, but that's a whole two extra characters in \LaTeX.}, and then conversely show that $x \in B$ implies $x \in A$, showing that $B \subset A$. Then $A = B$ by definition. Here's an example of this to prove Theorem \ref{distributive-law-2}:

\begin{proof}
Let $x \in A \cup (B \cap C)$. Then $x \in A$ or $x \in B \cap C$. If $x \in A$, $x \in A \cup B$ and $x \in A \cup C$, so $x \in (A \cup B) \cap (A \cup C)$. If $x \notin A$, $x \in B \cap C$, so $x \in A \cup B$ and $x \in A \cup C$, so $x \in (A \cup B) \cap (A \cup C)$. So $A \cup (B \cap C) \subset (A \cup B) \cap (A \cup C)$.

Now suppose $x \in (A \cup B) \cap (A \cup C)$. This implies $x \in A$, so $x \in A \cup (B \cap C)$. So $(A \cup B) \cap (A \cup C) \subset A \cup (B \cap C)$.

These two facts together suffice to show that the two sets are equal, so we are done.
\end{proof} 

\begin{definition}
Let $A$ and $U$ (called the \textbf{universe}) be sets. Suppose $A \subset U$. Then $A' = U \setminus A$ is the \textbf{complement} of $A$.
\end{definition}

\begin{theorem}[De Morgan's Laws]
Let $A$ and $B$ be subsets of some fixed set.

\begin{align}
(A \cup B)' = A' \cap B' \\
(A \cap B)' = A' \cup B'
\end{align}
\end{theorem}

These are easy to see with a Venn diagram or by comparing to the logical version of them you can find on Wikipedia. I would draw one here but doing that in \LaTeX \ is a pain in the ass. Sorry, just draw it on paper or Google it if you're curious.

\section{Maps}

Let $f: A \rightarrow B$ be a mapping from sets $A$ to $B$.

\begin{definition}
$f$ is \textbf{surjective} or \textbf{onto} if $\forall b \in B$, $\exists a \in A$ s.t. $f(a) = b$. $f$ is a \textbf{surjection}.
\end{definition}

\begin{definition}
$f$ is \textbf{injective} or \textbf{1-1} if $a \neq a' \implies f(a) \neq f(a')$, $a, a' \in A$. $f$ is an \textbf{injection}.
\end{definition}

If $f$ is 1-1 and $f(a) = f(a')$, then $a = a'$.

\begin{definition}
If $f$ is both injective and surjective, $f$ is \textbf{bijective} or a \textbf{bijection}.
\end{definition}

Notice that being bijective is a necessary and sufficient condition for being invertible.

Two sets have the same cardinality if there is a bijection between them.

\begin{proposition}
A composition $f \circ g : A \rightarrow C $ of two injective maps $f : A \rightarrow B$, $g: B \rightarrow C$ is injective. \\
A composition of two surjective maps is surjective. \\
A composition of two bijective maps is bijective.
\end{proposition}

\section{Relations, equivalence relations, partitions}

Let $S$ be a set and $s, t, u \in S$ throughout this section.

\begin{definition}
A \textbf{relation} $\bowtie$ on $S$ is a subset of $S \times S$. Write $s \bowtie t$ if $(s, t) \in \ \bowtie$.
\end{definition}

\begin{definition}
$\bowtie$ is \textbf{reflexive} if $s \bowtie s$ $\forall s \in S$. \\
$\bowtie$ is \textbf{symmetric} if $s \bowtie t \implies t \bowtie s$. \\
$\bowtie$ is \textbf{transitive} if $s \bowtie t$ and $t \bowtie u \implies s \bowtie u$. \\
$\bowtie$ is an \textbf{equivalence relation} if is reflexive, symmetric, and transitive.
\end{definition}

Of course the most familiar example of an equivalence relation is $=$. But consider also the set of lines in the plane and the relation $||$, where $l_1 \ || \ l_2$ means $l_1$ is parallel to $l_2$. Then $||$ is an equivalence relation. Likewise with the congruence operator $\cong$ on triangles in the plane.

\begin{definition}
A \textbf{partition} of $S$ is a collection of non-empty, mutually disjoint subsets whose union is $S$.
\end{definition}

To show that a collection of sets $\{ C_1, \ldots, C_n \}$ is a partition of $S$ for $n \ge 1$:

\begin{itemize}
\item Show that $C_i \neq \emptyset$ $\forall i$
\item Show that $C_i \cap C_j = \emptyset$ $\forall \ i \neq j$
\item Show that $x \in S \implies x \in C_i$ for some $i$
\end{itemize}

An example would be partitioning the plane with lines (possibly an infinite number).

Equivalence relations also partition the set into \textbf{equivalence classes}:

\begin{definition}
Let $\sim$ be an equivalence relation on $S$ and $x \in S$. \\
$[x] = \{ y \ | \ y \in S, x \sim y\}$ is the \textbf{equivalence class} of $x$.
\end{definition}

\begin{proposition}
$\{[x] \ | \ x \in S \}$ is a partition of $S$.
\end{proposition}

\section{Calculus and Analysis}

The following is taken from Spivak's {\it Calculus} \cite{spivak} and Ross' {\it Elementary Analysis} \cite{ross}. Examples often correspond to exercise in the texts and the order follows that of the books.

\subsection{Bounds, sup, inf, the Completeness Axiom}

Let $S \subset \mathbb{R}$, $S \neq \emptyset, m, M \in \mathbb{R}$. 

\begin{definition}
If $s_0 \in S$ and $s_0 \ge s$ $\forall s \in S$, write $\max S = s_0$. $s_0$ is the \textbf{maximum} of $S$.
\end{definition}

\begin{definition}
If $s_0 \in S$ and $s_0 \le s$ $\forall s \in S$, write $\min S = s_0$. $s_0$ is the \textbf{minimum} of $S$.
\end{definition}

\begin{definition}
If $s \leq M$ $\forall s \in S$, $M$ is an \textbf{upper bound} of $S$. S is \textbf{bounded above}.
\end{definition}

\begin{definition}
If $m \leq s$ $\forall s \in S$, $m$ is a \textbf{lower bound} of $S$. S is \textbf{bounded below}.
\end{definition}

\begin{definition}
If $S$ is both bounded above and bounded below, $S$ is \textbf{bounded}. So $\exists$ $m, M$ s.t. $S \subset [m, M]$.
\end{definition}

\begin{definition}
If $M$ is an upper bound and $M \leq B$ for all other upper bounds $B$, $M$ is a \textbf{least upper bound} or \textbf{supremum} of $S$. Write sup $S = M$.
\end{definition}

\begin{definition}
If $m$ is a lower bound and $m \geq b$ for all other lower bounds $b$, $m$ is a \textbf{greatest lower bound} or \textbf{infimum} of $S$. Write inf $S = m$.
\end{definition}

\begin{example}
sup $\{r \in \mathbb{R} : 0 \leq r < \sqrt{2}\} = \sqrt{2}$.
\end{example}

The least upper bound and greatest lower bound are unique. Imagine having a bunch of points on a number line and moving a pencil from left to right until it hit upon a point on the line. That would be an infimum. Going from the opposite direct, right to left, would give a supremum. Note that the infimum and supremum do not need to be in $S$.

\begin{axiom}[Completeness Axiom]
Every nonempty subset $S$ of $\mathbb{R}$ that is bounded above has a least upper bound $\sup S \in\mathbb{R}$.
\end{axiom}

\begin{corollary}
Every nonempty subset $S$ of $\mathbb{R}$ that is bounded below has a greatest lower bound $\inf S \in\mathbb{R}$.
\end{corollary}

\begin{proof}
Since $S$ is bounded below, $\exists$ $m \in \mathbb{R}$ s.t. $m \leq s$, $s \in S$.

Let $-S = \{ -s : s \in S \}$. Then $-m \ge -s$, so $-S$ is bounded above. So $\sup -S$ exists.

It can be shown that $\inf S = - \sup -S$, so $\inf S$ exists.

\end{proof}

\begin{proposition}
Say $\sup S \in S$. Then $\sup S \ge s$ $\forall s \in S$, so by definition $\sup S = \max S$.
\end{proposition}

\begin{proposition} \label{bound-comparison}
Let $S$ be bounded and nonempty. Then $\inf S$ and $\sup S$ exist. Let $s \in S$. Then $\inf S \le s \le \sup S$.
So $\inf S \le \sup S$.
\end{proposition}

\begin{proposition}
In Proposition \ref{bound-comparison}, suppose $\inf S = \sup S$. Then $\inf S = s = \sup S$, so $S = \{s\}$.
\end{proposition}

\subsection{Limits}


\begin{definition}[$(\epsilon, \delta)$ limit of a function]

Let $f: \mathbb{R} \to \mathbb{R}$ be a function. 

\begin{equation}
\lim_{x \to a} f(x) = L
\end{equation}

if for every $\epsilon > 0$ there exists $\delta > 0$ such that if $0 < |x-a| <
\delta$, then $|f(x) - L| < \epsilon$.
 
\end{definition}

This formalizes the idea of being able to take $f(x)$ as close to $L$ as we want
by making $x$ sufficiently close to $a$.

Actually proving these winds up being an exercise in grappling with bullshit
absolute value expressions. Your basic plan of attack will probably be to let
$\epsilon > 0$ and find a suitable expression for $\delta$ in terms of
$\epsilon$ so that $|f(x) -L| < \epsilon$ once $|x-a|< \delta$ is assumed.

\begin{example} 

\emph{Show that $\lim_{x \to 1} (3x-1) = 2$}.

Substituting $f(x) = 3x-1$, $a = 1$, and $L = 2$ into the definition of a limit,
we want to show that

\begin{equation}
|x - 1| < \delta \implies |3x - 3| < \epsilon.
\end{equation}

This example was clearly chosen because the algebra is easy and the algebra
works out like so: $|3x-3| = |3(x-1)| = 3|x-1| < \epsilon \implies |x-1| <
\epsilon/3$, so $\delta = \epsilon/3$ is a suitable choice.

Then $|x - 1| < \epsilon/3 \implies |3x-3| = |(x - 1) + (2x-2)| \leq |x-1| +
|2x-2| = |x-1| + 2|x-1| < \epsilon/3 + 2 \cdot \epsilon/3 = \epsilon,$ so we are
done. $\blacksquare$

Note that we have used Eq. \ref{triangle-inequality} above.
 
\end{example}

As you can no doubt surmise, with harder examples this shit gets really depressing.

Limits compose the way you'd expect:
\begin{proposition}
Suppose $\lim_{x \to a} f(x) = L$ and $\lim_{x \to a} g(x) = M$. Then

\begin{align}
\lim_{x \to a} f(x) + g(x) & = L + M \\
\lim_{x \to a} f(x)g(x) & = L \cdot M \\
\lim_{x \to a} \left(\frac{f}{g}\right)(x) & = \frac{L}{M}
\end{align}

Assuming everything above is defined.

\end{proposition}

If you can show that the positive ($\lim_{x \to a^{+}} f(x)$) and negative
($\lim_{x \to a^{-}} f(x) $) limits of a function are
different, it follows that the limit does not exist.


\subsection{Continuity}

\begin{definition}

$f$ is \textbf{continuous} at $a$ if

\begin{equation}
\lim_{x \to a} f(x) = f(a).
\end{equation}

\end{definition}

Of course continuous functions compose as you'd expect.

\begin{proposition}

If $f$ and $g$ are continuous at $a$, then $f+g$ and $f \cdot g$ is continuous
at $a$. If $g(a) \neq 0$, $1/g$ is continuous at $a$.

\end{proposition}

\begin{proof}

This follows from the definition of continuity and the previous limit
theorem. $\lim_{x \to a} (f(x) + g(x)) = \lim_{x \to a} f(x) + \lim_{x \to a}
g(x) = f(a) + g(a)$, so $f + g$ is continuous at $a$ by definition of
continuity. Replacing $+$ with $\cdot$ and using the previous limit theorem, the
rest of the result follows.

\end{proof}

The key thing that happens with a continuous function is that there's an
interval around $a$ that will share the properties of $f(a)$, like sign.

\subsection{Derivatives}

\begin{definition} 
$f$ is differentiable at $a$ if

\begin{equation}
\lim_{h \to 0} \frac{f(x+h) - f(x)}{h}
\end{equation}

exists.
\end{definition}

Recall the geometric interpretation of $f'(x)$ as being the slope of a line
tangent to $f(x)$; $f'(x)$ is like a secant line on a function between two
points of infinitely small distance. The physical interpretation of $f'(x)$ as
velocity and $f''(x)$ as acceleration should be familiar.

\begin{proposition}[Product Rule] 

If $f$ and $g$ are differentiable, 

\begin{equation}
(f \cdot g)' = f'g + g'f.
\end{equation}


\end{proposition} 

This generalizes recursively; $(f \cdot g \cdot h)' = f'gh + fg'h + fgh'$, and
so on. Notice the symbolic symmetry of it: sum the product of all the functions,
differentiating each one in turn.

\begin{proposition}[Chain Rule]

If $f$ and $g$ are differentiable,

\begin{equation}
(f \circ g)'(x) = f'(g)g'(x).
\end{equation}


\end{proposition}

\subsubsection{Derivative formulas}

\begin{equation}
\left(\frac{f}{g}\right)' = \frac{f'g - g'f}{g^2}
\end{equation}

\begin{equation}
(x^n)' = nx^{n-1}
\end{equation}

\section{Books I copied this stuff from}

\begin{thebibliography}{9}

\bibitem{ross}
  Kenneth A. Ross,
  \emph{Elementary Analysis: The Theory of Calculus}.
  Springer-Verlag,
  1st Edition,
  2013.

\bibitem{smith}
  Geoff Smith,
  \emph{Introductory Mathematics: Algebra and Analysis},
  Springer-Verlag,
  1998.

\bibitem{spivak}
  Michael Spivak,
  \emph{Calculus}.
  Publish or Perish,
  4th Edition,
  2008.

\bibitem{strichartz}
  Robert Strichartz,
  \emph{The Way of Analysis}.
  Jones and Bartlett Publishers,
  2000.
  
\end{thebibliography}

\section{License}

This document is freely shareable under the terms of the GNU Free Documentation
license; see LICENSE in this document's directory for more information.

\end{document}

